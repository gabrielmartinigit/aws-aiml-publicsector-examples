{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Amazon Rekognition, Amazon Textract e Amazon Comprehend\n",
    "\n",
    "Vamos utilizar algumas das APIs de alguns serviços de inteligência artificial para extair informações de imagens e textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # aws python sdk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import IPython.display as disp\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '../sample-data/gov/images/'\n",
    "text_dir = '../sample-data/gov/text/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    with open(filename, \"rb\") as imageFile:\n",
    "      f = imageFile.read()\n",
    "      return bytearray(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(labels):\n",
    "    data = {'Label':[], 'Confidence':[]}\n",
    "    for label in labels:\n",
    "        data['Label'].append(label['Name'])\n",
    "        data['Confidence'].append(label['Confidence'])\n",
    "    return pd.DataFrame(data)[['Label', 'Confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_box(bbox, size):\n",
    "    if len(bbox) != 4:\n",
    "        return None\n",
    "    return [ \n",
    "        bbox['Left']*size[0], bbox['Top']*size[1],\n",
    "        (bbox['Left']*size[0])+bbox['Width']*size[0], \n",
    "        (bbox['Top']*size[1])+bbox['Height']*size[1]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(filename, bbox, color, size):\n",
    "    img = Image.open(filename)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.line([(bbox[0], bbox[1]), (bbox[2], bbox[1])], fill=color, width=4)\n",
    "    draw.line([(bbox[2], bbox[1]), (bbox[2], bbox[3])], fill=color, width=4)\n",
    "    draw.line([(bbox[2], bbox[3]), (bbox[0], bbox[3])], fill=color, width=4)\n",
    "    draw.line([(bbox[0], bbox[1]), (bbox[0], bbox[3])], fill=color, width=4)\n",
    "    del draw\n",
    "    plt.figure(figsize = (20,size))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lines_confidence(lines, lenght):\n",
    "    try:\n",
    "        for l in range(1, lenght):\n",
    "            print(lines[l]['Text'] + '({})'.format(lines[l]['Confidence']))\n",
    "    except Exception as e:\n",
    "        print(\"Too long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(name):\n",
    "    try:\n",
    "        response = rekognition.delete_collection(\n",
    "            CollectionId=name\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Collection not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_classifier():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_entity():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Rekognition\n",
    "\n",
    "O Amazon Rekognition facilita a adição de análises de imagens e vídeos aos seus aplicativos. Basta fornecer uma imagem ou um vídeo à API do Amazon Rekognition, e o serviço poderá identificar objetos, pessoas, texto, cenas e atividades. \n",
    "\n",
    "Documentação: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html\n",
    "\n",
    "_fontes das imagens utilizadas:_ \n",
    "* http://agenciabrasil.ebc.com.br/\n",
    "* http://g1.globo.com/\n",
    "* https://www.jornalterceiravia.com.br/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api client\n",
    "rekognition = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'carro.jpg', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_text(\n",
    "    Image={'Bytes': load_image(image_dir + 'carro.jpg')}\n",
    ")\n",
    "\n",
    "for i in response['TextDetections']:\n",
    "    if i['Confidence'] >= 95:\n",
    "        print( '%s - Confidence[%f]' % (i['DetectedText'], i['Confidence']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'agenciabrasil-4.jpg', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_labels(\n",
    "    Image={'Bytes': load_image(image_dir + 'agenciabrasil-4.jpg')},\n",
    "    MaxLabels=5,\n",
    "    MinConfidence=70\n",
    ")\n",
    "\n",
    "convert_to_dataframe(response['Labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'arma.jpg', width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_moderation_labels(\n",
    "    Image={'Bytes': load_image(image_dir + 'arma.jpg')},\n",
    "    MinConfidence=70\n",
    ")\n",
    "\n",
    "convert_to_dataframe(response['ModerationLabels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconhecimento de pessoas públicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'agenciabrasil-2.jpg', width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.recognize_celebrities(\n",
    "    Image={'Bytes': load_image(image_dir + 'agenciabrasil-2.jpg')}\n",
    ")\n",
    "\n",
    "img = Image.open(image_dir + 'agenciabrasil-2.jpg')\n",
    "bbox = create_bounding_box(response['CelebrityFaces'][0]['Face']['BoundingBox'], img.size )\n",
    "confidence = response['CelebrityFaces'][0]['Face']['Confidence']\n",
    "name = response['CelebrityFaces'][0]['Name']\n",
    "\n",
    "print(name, confidence)\n",
    "draw_bounding_box(image_dir + 'agenciabrasil-2.jpg', bbox, 'red', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'agenciabrasil-5.jpg', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_faces(\n",
    "    Image={'Bytes': load_image(image_dir + 'agenciabrasil-5.jpg')},\n",
    "    Attributes=['ALL']\n",
    ")\n",
    "\n",
    "age = response['FaceDetails'][0]['AgeRange']['High']\n",
    "gender = response['FaceDetails'][0]['Gender']['Value']\n",
    "\n",
    "print(age, gender)\n",
    "\n",
    "age = response['FaceDetails'][1]['AgeRange']['High']\n",
    "gender = response['FaceDetails'][1]['Gender']['Value']\n",
    "\n",
    "print(age, gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'jk-1.jpg', width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'jk-2.jpg', width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.compare_faces(\n",
    "    SourceImage={'Bytes': load_image(image_dir + 'jk-1.jpg')},\n",
    "    TargetImage={'Bytes': load_image(image_dir + 'jk-2.jpg')}\n",
    ")\n",
    "\n",
    "imgA = Image.open(image_dir + 'jk-1.jpg')\n",
    "imgB = Image.open(image_dir + 'jk-2.jpg')\n",
    "\n",
    "similarity = response['FaceMatches'][0]['Similarity']\n",
    "bboxA = create_bounding_box( response['SourceImageFace']['BoundingBox'], imgA.size )\n",
    "bboxB = create_bounding_box( response['FaceMatches'][0]['Face']['BoundingBox'], imgB.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Similarity: {}'.format( similarity ) )\n",
    "if bboxA: draw_bounding_box(image_dir + 'jk-1.jpg', bboxA, 'red', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bboxB: draw_bounding_box(image_dir + 'jk-2.jpg', bboxB, 'white', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca por faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Rekognition possui uma feature para que possamos criar coleções de faces, efetuando uma busca otimizada ao receber uma nova face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'tiririca-1.jpg', width='400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    delete_collection(\"Deputados\")\n",
    "    response = rekognition.create_collection(\n",
    "        CollectionId='Deputados'\n",
    "    )\n",
    "    faces = {\n",
    "        'Tiririca': image_dir + 'tiririca-1.jpg'\n",
    "    }\n",
    "    for ext_id, image_name in faces.items():\n",
    "        response = rekognition.index_faces(\n",
    "            CollectionId='Deputados',\n",
    "            Image={'Bytes': load_image(image_name)},\n",
    "            ExternalImageId=ext_id,\n",
    "        )\n",
    "        if len(response['FaceRecords']) > 0:\n",
    "            for i in response['FaceRecords']:\n",
    "                print( ext_id, i['Face']['FaceId'])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos enviar uma imagem diferente da utilizada na coleção e buscar por faces conhecidas pela coleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(image_dir + 'tiririca-2.jpg', width='400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = rekognition.search_faces_by_image(\n",
    "    CollectionId='Deputados',\n",
    "    Image={ 'Bytes': load_image( image_dir + 'tiririca-2.jpg') },\n",
    "    MaxFaces=10\n",
    ")['FaceMatches']\n",
    "\n",
    "print('# Mached faces in the collection: {}'.format( len(faces)))\n",
    "print('FaceId: {} - Similarity: {}'.format(faces[0]['Face']['ExternalImageId'], faces[0]['Similarity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Textract\n",
    "\n",
    "O Amazon Textract é um serviço que extrai automaticamente texto e dados de documentos digitalizados. O Amazon Textract vai além do simples OCR (Reconhecimento óptico de caracteres) para também identificar o conteúdo de campos em formulários e informações armazenadas em tabelas.\n",
    "\n",
    "Documentação: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api client\n",
    "textract = boto3.client('textract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Síncrono com suporte a documentos JPEG e PNG. Assíncrono com suporte a dcoumentos JPEG, PNG e PDF. Neste exemplo estamos utilizando o método síncrono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.Image(text_dir + 'constituicao-pg220.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = textract.detect_document_text(\n",
    "    Document={\n",
    "        'Bytes': load_image(text_dir + 'constituicao-pg220.jpg')\n",
    "    }\n",
    ")\n",
    "\n",
    "text = response['Blocks'][1]['Text'] # storing text to use with Comprehend\n",
    "\n",
    "print_lines_confidence(response['Blocks'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox on the first line\n",
    "img = Image.open(text_dir + 'constituicao-pg220.jpg')\n",
    "bbox = create_bounding_box( response['Blocks'][1]['Geometry']['BoundingBox'], img.size )\n",
    "draw_bounding_box(text_dir + 'constituicao-pg220.jpg', bbox, 'red', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Comprehend\n",
    "\n",
    "O Amazon Comprehend é um serviço de Natural Language Processing (NLP – Processamento de linguagem natural) que usa Machine Learning para encontrar insights e relações dentro de documentos em texto. Nenhuma experiência de Machine Learning necessária.\n",
    "\n",
    "Também é possível trabalhar de forma síncrona e assíncrona para análise de texto. Neste exemplo estamos utilizando o método síncrono.\n",
    "\n",
    "Documentação: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api client\n",
    "comprehend = boto3.client('comprehend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)\n",
    "\n",
    "response = comprehend.detect_dominant_language(Text = text)\n",
    "\n",
    "print(response['Languages'][0]['LanguageCode'] + ' - Confidence: {}'.format(response['Languages'][0]['Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend.detect_entities(\n",
    "    Text = text,\n",
    "    LanguageCode = 'pt'\n",
    ")\n",
    "\n",
    "for e in range(0, len(response['Entities'])):\n",
    "    print(response['Entities'][e]['Type'] + ' - ' + response['Entities'][e]['Text'] + ' - ' + str(response['Entities'][e]['Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de palavras chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend.detect_key_phrases(\n",
    "    Text = text,\n",
    "    LanguageCode = 'pt'\n",
    ")\n",
    "\n",
    "print(response['KeyPhrases'][0]['Text'])\n",
    "print(response['KeyPhrases'][1]['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend.detect_sentiment(\n",
    "    Text = text,\n",
    "    LanguageCode = 'pt'\n",
    ")\n",
    "\n",
    "print(response['Sentiment'] + ' - Accuracy: {}'.format(response['SentimentScore']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Morfológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend.detect_syntax(\n",
    "    Text = text,\n",
    "    LanguageCode = 'pt'\n",
    ")\n",
    "\n",
    "for t in range(0, len(response['SyntaxTokens'])):\n",
    "    print(response['SyntaxTokens'][t]['Text'] + ' - ' + response['SyntaxTokens'][t]['PartOfSpeech']['Tag'] + ' - ' + str(response['SyntaxTokens'][t]['PartOfSpeech']['Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpando os recursos criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekognition collection\n",
    "delete_collection('Deputados')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
